{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing the necessary modules. We'll use matplotlib for plotting, pytorch as our machine learning framework, the time module for tracking the length of calculations, and numpy for array manipulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's acquire and load the MNIST dataset. Since this is a common dataset, the torchvision module has a class that simplifies this procedure. The following lines of code downloads the MNIST dataset, which is conveniently divided into a test and training set. The dataset is stored in the directory assigned to ``data_dir``. \n",
    "\n",
    "The MNIST dataset provides images in a Python Image Library (PIL) format. We'll have torch automatically apply a transform to these images to convert them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 60000\n",
      "Number of images in test set: 10000\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "pil2tnsr = torchvision.transforms.ToTensor()\n",
    "\n",
    "train = torchvision.datasets.MNIST(data_dir, train=True, download=True, transform=pil2tnsr)\n",
    "test = torchvision.datasets.MNIST(data_dir, train=False, download=True, transform=pil2tnsr)\n",
    "\n",
    "print(f'Number of images in training set: {len(train)}')\n",
    "print(f'Number of images in test set: {len(test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the MNIST dataset, let's see what images look like. The variable ``index`` specifies an image number in our training set. Change it to explore other entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label: 3\n",
      "Image size: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "img, label = train[index]\n",
    "\n",
    "tensr2pil = torchvision.transforms.ToPILImage()\n",
    "img_pil = tensr2pil(img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_pil)\n",
    "\n",
    "print(f'Image label: {label}')\n",
    "print(f'Image size: {img_pil.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides useful tools to simplify loading and processing our data. Since we used torchvision to get the MNIST dataset,  ``train`` and ``test`` are already objects which PyTorch recognizes as datasets. We can pass them to DataLoader, which simplifies iterating through the dataset. Setting batch_size to 8 means we'll iterate through 8 images/labels at a time, and setting shuffle to True means that data is shuffled after we have iterated through the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our neural network. We use a fairly simple convolutional neural network architecture. The first part of the network has three repetitions of a convolutional layer with a ReLU activation followed by a maxpooling layer. Afterwards, there are two fully connected layers with a ReLU activation between them.\n",
    "\n",
    "![title](nn_relu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.dense1 = nn.Linear(64, 64)\n",
    "        self.dense2 = nn.Linear(64, 10)\n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2), stride=(2,2))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Conv/pool: (Batch size, 1, 28,28 ) -> (Batch size, 32, 24, 24) -> (Batch size, 32, 12, 12)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        #Conv/pool: (Batch size, 32, 12, 12) -> (Batch size, 32, 8, 8) -> (Batch size, 32, 4, 4)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        #Conv/pool: (Batch size, 32, 4, 4) -> (Batch size, 64, 2, 2) -> (Batch size, 64, 1, 1)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        #Flatten: (Batch size, 64, 1, 1) -> (Batch size, 64*1*1)\n",
    "        x = x.view(-1, 64)\n",
    "        \n",
    "        #Dense Layer 1: (Batch size, 64) -> (Batch size, 64)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        #Dense Layer 2: (Batch size, 64) -> (Batch size, 10)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate our neural network. We'll also need to choose a loss function. Here we've selected Cross Entropy Loss, which is appropriate when you want your neural network to assign your input to one of several classes. We've selected the Adam optimization algorithm to optimize our network weights such that they minimize our loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have everything we need to go. This code iterates through our data, comparing the model prediction with the labels, and updating our weights to improve our neural networks ability. The ``num_epochs`` parameters determine how many time we cycle through our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2\n",
      "Loss: 0.30464214020967484\n",
      "Loss: 0.1003953853920102\n",
      "Loss: 0.0807381663620472\n",
      "Finished in 107.92s\n",
      "Accuracy on train set: 95.54833333333333\n",
      "Epoch: 2/2\n",
      "Loss: 0.04743631257861853\n",
      "Loss: 0.05301460570842027\n",
      "Loss: 0.05167941872775555\n",
      "Finished in 100.07s\n",
      "Accuracy on train set: 98.435\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "num_epochs = 2 \n",
    "\n",
    "#Initalize counters\n",
    "running_loss = 0.0\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "    t_start = time.time()\n",
    "    \n",
    "    #Iterate through mini-batches\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        \n",
    "        #Optimize the neural network\n",
    "        inputs, labels = data\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Track the accuracy of its predictions\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        #Track the loss function, and output it regularly\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'Loss: {running_loss/2000}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    \n",
    "    print(f'Finished in {time.time() - t_start:.2f}s')\n",
    "    print(f'Accuracy on train set: {100*correct/total}')\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our neural network is performing well. After 2 epochs of training, our neural network can correctly label images in the training set with 98.4% accuracy. How does it do on data it hasn't seen before? Let's check it's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.85\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "total = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        y_pred = model(inputs)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy on test set: {100*correct/total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slightly higher accuracy on the test set than on the training set. This means we haven't overfitted the model, or in other words, in generalizes well. \n",
    "\n",
    "Finally, let's see our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 4, 6, 5, 1, 0, 9, 5])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it, a fully trained and functioning neural network capable of identifying handwritten digits with 98% accuracy. Similar networks have been deployed before to help read addresses on envelopes and writing on cheques.\n",
    "\n",
    "Let's summarize the ground we covered in this notebook:\n",
    "1. Loading Data\n",
    "2. Creating a neural network\n",
    "3. Selecting a loss function\n",
    "4. Optimizing your model\n",
    "5. Calculating the train and test set accuracy\n",
    "6. Making predictions with your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process used in this notebook is typical of machine learning projects. The code here is a good starting template for your own projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
